{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,input,seq_len):\n",
    "        \"\"\"\n",
    "        input: full corpus\n",
    "        seq_len: number of features\n",
    "        \"\"\"\n",
    "        self.input = input \n",
    "        self.seq_len = seq_len\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        \"\"\"\n",
    "        return one item in the dataset\n",
    "        \"\"\"\n",
    "        return torch.tensor(self.input[item:item+self.seq_len]), torch.tensor(self.input[item+1:item+1+self.seq_len])\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        return the length of the dataset\n",
    "        \"\"\"\n",
    "        return len(self.input) - self.seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, dv, dh, num_layers):\n",
    "        super(MyRNN,self).__init__()\n",
    "        self.d_in = dv #num vocab\n",
    "        self.d_h = dh #hidden state\n",
    "        self.layer = num_layers\n",
    "        self.rnn = nn.RNN(input_size = dv,hidden_size = dh,num_layers = num_layers,batch_first = True, bias = True )\n",
    "        self.fc =nn.Linear(dh,dv)\n",
    "        if torch.cuda.is_available():\n",
    "          self.device = torch.device('cuda')\n",
    "        else:\n",
    "          self.device = torch.device('cpu')\n",
    "    \n",
    "    def forward(self, batch_size, x):\n",
    "        h0 = torch.zeros(1,batch_size,self.d_h).float().to(self.device)\n",
    "        result, ht = self.rnn(x,h0)\n",
    "        result = self.fc(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get corpus\n",
    "txt = open('shakespeare.txt','r')\n",
    "corpus = txt.read()\n",
    "corpus = re.sub(\" +\",' ',corpus).strip()\n",
    "txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From fairest creatures we desire increase,\\nThat thereby beauty's rose might never die,\\nBut as the riper should by time decease,\\nHis tender heir might bear his memory:\\nBut thou contracted to thine own bright eyes,\\nFeed'st thy light's flame with self-substantial fuel,\\nMaking a famine where abundance lies,\\nThy self thy foe, to thy sweet self too cruel:\\nThou that art now the world's fresh ornament,\\nAnd only herald to the gaudy spring,\\nWithin thine own bud buriest thy content,\\nAnd tender churl mak'st waste in niggarding:\\n Pity the world, or else this glutton be,\\n To eat the world's due, by the grave and thee.\\n\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_list = [i.strip()+\"\\n\" for i in re.split('[0-9]',corpus) if len(i)>1]\n",
    "corpus = re.sub('[0-9]','',corpus)\n",
    "corpus_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build dictionary and word embedding(one hot)\n",
    "letters = list(corpus.strip())\n",
    "bow = set(letters)\n",
    "num_vocab = len(bow)\n",
    "dictionary={word:num for (num,word) in enumerate(bow)}\n",
    "word_vectors = []\n",
    "for 诗 in corpus_list:\n",
    "    corpus_vectors = []\n",
    "    for j in 诗:\n",
    "        v = np.zeros(num_vocab)\n",
    "        v[dictionary[j]] = 1\n",
    "        corpus_vectors.append(v)\n",
    "    word_vectors.append(corpus_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Epoch:1/300 ======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 10.59it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 10.59it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 10.51it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 11.23it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 11.11it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 10.62it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\leoli\\Desktop\\卷王的自我修养\\RNN\\RNN_model.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/leoli/Desktop/%E5%8D%B7%E7%8E%8B%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB/RNN/RNN_model.ipynb#ch0000007?line=32'>33</a>\u001b[0m     total_train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/leoli/Desktop/%E5%8D%B7%E7%8E%8B%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB/RNN/RNN_model.ipynb#ch0000007?line=33'>34</a>\u001b[0m opt\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/leoli/Desktop/%E5%8D%B7%E7%8E%8B%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB/RNN/RNN_model.ipynb#ch0000007?line=34'>35</a>\u001b[0m total_train_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/leoli/Desktop/%E5%8D%B7%E7%8E%8B%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB/RNN/RNN_model.ipynb#ch0000007?line=35'>36</a>\u001b[0m opt\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/leoli/Desktop/%E5%8D%B7%E7%8E%8B%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB/RNN/RNN_model.ipynb#ch0000007?line=36'>37</a>\u001b[0m epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m total_train_loss\n",
      "File \u001b[1;32mc:\\Users\\leoli\\Desktop\\卷王的自我修养\\env\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\leoli\\Desktop\\卷王的自我修养\\env\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#training\n",
    "epochs = 300\n",
    "d_hidden = 1024\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "model = MyRNN(num_vocab,d_hidden,1)\n",
    "model.to(device)\n",
    "loss_Func = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(model.parameters(),lr = 0.005)\n",
    "pre_loss = float('inf')\n",
    "for epoch in range(epochs):\n",
    "    print(f\"====================== Epoch:{epoch+1}/{epochs} ======================\")\n",
    "    epoch_loss = 0.0\n",
    "    # num_ = 0\n",
    "    for 诗 in word_vectors:\n",
    "        # num_+=1\n",
    "        # print(f'诗：{num_}')\n",
    "        ds = MyDataset(诗,10)\n",
    "        dl = DataLoader(ds, batch_size= 128)\n",
    "        total_train_loss = torch.tensor(0.0)\n",
    "        total_train_loss = total_train_loss.to(device)\n",
    "        for label, items in enumerate(tqdm(dl)):\n",
    "            batch = items[0]\n",
    "            input = batch.float()\n",
    "            batch_size = batch.shape[0]\n",
    "            output = items[1]\n",
    "            input = input.to(device)\n",
    "            output = output.to(device)\n",
    "            pred = model(batch_size,input)\n",
    "            loss = loss_Func(pred, output)\n",
    "            total_train_loss += loss\n",
    "        opt.zero_grad()\n",
    "        total_train_loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss += total_train_loss\n",
    "    print(f'Epoch: {epoch+1}, epoch loss: {epoch_loss}')\n",
    "    if (epoch+1)%100 == 0:\n",
    "        time.sleep(300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Epoch:1/20 ======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 45.31it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 205.94it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 143.32it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 209.02it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 170.51it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 204.04it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 187.15it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 172.10it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 192.26it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 198.91it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 174.79it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 196.37it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 175.98it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 220.73it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 167.35it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 206.69it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 198.58it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 194.94it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 215.56it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 171.90it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 189.61it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 181.10it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 209.03it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 191.38it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 192.21it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 156.02it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 219.12it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 173.69it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 173.71it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 213.45it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 215.95it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 204.44it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 201.90it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 204.68it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 176.60it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 234.44it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 166.88it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 159.97it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 206.32it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 208.08it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 184.65it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 139.02it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 174.50it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 122.62it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 214.14it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 166.78it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 176.05it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 185.39it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 208.83it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 215.03it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 209.52it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 172.99it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 239.05it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 181.77it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 240.80it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 166.94it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 199.86it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 186.87it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 188.90it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 205.51it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 198.22it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 208.82it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 212.02it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 178.65it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 188.92it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 224.04it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 189.96it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 204.49it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 172.60it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 183.53it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 180.47it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 172.05it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 191.43it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 184.87it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 171.38it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 212.93it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 189.76it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 217.17it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 178.06it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 188.16it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 219.90it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 191.19it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 230.13it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 176.40it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 196.86it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 152.16it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/yul080/Test/myrnn.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226b6173746e65722d6d6c2e64796e616d69632e756373642e656475222c2275736572223a2279756c303830227d/home/yul080/Test/myrnn.ipynb#ch0000008vscode-remote?line=21'>22</a>\u001b[0m     total_train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226b6173746e65722d6d6c2e64796e616d69632e756373642e656475222c2275736572223a2279756c303830227d/home/yul080/Test/myrnn.ipynb#ch0000008vscode-remote?line=22'>23</a>\u001b[0m opt\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226b6173746e65722d6d6c2e64796e616d69632e756373642e656475222c2275736572223a2279756c303830227d/home/yul080/Test/myrnn.ipynb#ch0000008vscode-remote?line=23'>24</a>\u001b[0m total_train_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226b6173746e65722d6d6c2e64796e616d69632e756373642e656475222c2275736572223a2279756c303830227d/home/yul080/Test/myrnn.ipynb#ch0000008vscode-remote?line=24'>25</a>\u001b[0m opt\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226b6173746e65722d6d6c2e64796e616d69632e756373642e656475222c2275736572223a2279756c303830227d/home/yul080/Test/myrnn.ipynb#ch0000008vscode-remote?line=25'>26</a>\u001b[0m epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m total_train_loss\n",
      "File \u001b[0;32m~/ayay/lib/python3.8/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/ayay/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#optional, for extra training\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    print(f\"====================== Epoch:{epoch+1}/{epochs} ======================\")\n",
    "    epoch_loss = 0.0\n",
    "    # num_ = 0\n",
    "    for 诗 in word_vectors:\n",
    "        # num_+=1\n",
    "        # print(f'诗：{num_}')\n",
    "        ds = MyDataset(诗,10)\n",
    "        dl = DataLoader(ds, batch_size= 258)\n",
    "        total_train_loss = torch.tensor(0.0)\n",
    "        total_train_loss = total_train_loss.to(device)\n",
    "        for label, items in enumerate(tqdm(dl)):\n",
    "            batch = items[0]\n",
    "            input = batch.float()\n",
    "            output = items[1]\n",
    "            input = input.to(device)\n",
    "            output = output.to(device)\n",
    "            pred = model(input)\n",
    "            loss = loss_Func(pred, output)\n",
    "            total_train_loss += loss\n",
    "        opt.zero_grad()\n",
    "        total_train_loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss += total_train_loss\n",
    "    print(f'Epoch: {epoch+1}, epoch loss: {epoch_loss}')\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a dictionary for generation\n",
    "result_dict = {v:k for k,v in dictionary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text generating\n",
    "start = word_vectors[0][0]#[np.random.choice(len(word_vectors))]\n",
    "func = nn.Softmax(dim=1)\n",
    "word = ''\n",
    "count = 0\n",
    "while count<14:\n",
    "    out = func(model(torch.tensor([start]).float().to(device)))\n",
    "    out = out.cpu().detach().numpy()\n",
    "    num = np.random.choice(np.arange(len(out[0])),p = out[0])\n",
    "    pred = result_dict[num]\n",
    "    if pred == \"\\n\":\n",
    "      count+=1\n",
    "    word = word+pred\n",
    "    start = np.zeros(num_vocab)\n",
    "    start[dictionary[pred]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ongreme thinede,\n",
      "Whe.\n",
      "I cass berereresty withes atheesthive, me,\n",
      "Tharingast meforofofe,\n",
      "Tonowat whe by med,\n",
      "Thadongomymely prowor as me prathas I t sthanowofas merelarofas beded os isssthed benesaly beres med.\n",
      "Whe bed theere,\n",
      "Astherinalourenousthis thin ast sthave I meathindded I me wins moulinorus mave The,\n",
      "As fo hinofontofofs mes me fathered berelout becoucadesserinountovinorous thistersthed my t dinscorakemmeallat mmellofofeeresst me,\n",
      "Mivanouthenerowigs,\n",
      "That cedatorest onous gro s cathed ales astheat ined mes ad grestherenombes med I be,\n",
      "Andowofisthake,\n",
      "Mof festhathymy wigresthasthasthes bed thin med,\n",
      "Thererthader mad athys's t st stronones ssthalofos medofat sse pre bes my t as as bed ds anofondin grasthathesthan thesthe'sedst,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "torch.save(model.state_dict(), 'RNN_word_generation_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model\n",
    "d_hidden = 1024\n",
    "params = torch.load(\"RNN_word_generation_model.pth\",map_location=torch.device('cpu'))\n",
    "model = MyRNN(num_vocab,d_hidden,1)\n",
    "model.load_state_dict(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyRNN(\n",
       "  (rnn): RNN(61, 1024, batch_first=True)\n",
       "  (fc): Linear(in_features=1024, out_features=61, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus = word_vectors[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = MyDataset(test_corpus,10)\n",
    "dl =DataLoader(ds, batch_size= 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/55 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for label, items in enumerate(tqdm(dl)):\n",
    "    a= items\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = a[0]\n",
    "test_output = a[1]\n",
    "h0 = torch.zeros(1,128,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(61, 1024, batch_first=True)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.RNN(61,1024,1,batch_first = True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred,test_hidden = model(test_input.float(),h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 10, 1024])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer = nn.Linear(1024,61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 10, 61])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = first_layer(test_pred)\n",
    "test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3774, dtype=torch.float64, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_f(test_pred, test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0700,  0.0105,  0.0082,  ..., -0.0171,  0.0064, -0.0104],\n",
       "          [ 0.0188,  0.0123,  0.0245,  ..., -0.0013,  0.0298,  0.0029],\n",
       "          [ 0.0475,  0.0171, -0.0154,  ..., -0.0210,  0.0408,  0.0239],\n",
       "          ...,\n",
       "          [ 0.0053,  0.0143,  0.0013,  ..., -0.0002,  0.0071,  0.0186],\n",
       "          [ 0.0333,  0.0299,  0.0022,  ..., -0.0111,  0.0458,  0.0064],\n",
       "          [ 0.0597,  0.0354, -0.0003,  ..., -0.0095,  0.0323,  0.0249]],\n",
       " \n",
       "         [[ 0.0353,  0.0153,  0.0278,  ..., -0.0006,  0.0239, -0.0012],\n",
       "          [ 0.0481,  0.0245, -0.0049,  ..., -0.0159,  0.0385,  0.0187],\n",
       "          [ 0.0317,  0.0097,  0.0027,  ..., -0.0309,  0.0183,  0.0512],\n",
       "          ...,\n",
       "          [ 0.0333,  0.0298,  0.0020,  ..., -0.0109,  0.0458,  0.0060],\n",
       "          [ 0.0599,  0.0355, -0.0002,  ..., -0.0096,  0.0323,  0.0248],\n",
       "          [ 0.0293,  0.0155,  0.0078,  ..., -0.0052,  0.0513,  0.0357]],\n",
       " \n",
       "         [[ 0.0426,  0.0123,  0.0100,  ..., -0.0207,  0.0225,  0.0073],\n",
       "          [ 0.0341,  0.0031,  0.0095,  ..., -0.0249,  0.0220,  0.0494],\n",
       "          [ 0.0471,  0.0140,  0.0091,  ..., -0.0371,  0.0403,  0.0242],\n",
       "          ...,\n",
       "          [ 0.0602,  0.0356, -0.0005,  ..., -0.0095,  0.0324,  0.0248],\n",
       "          [ 0.0294,  0.0155,  0.0080,  ..., -0.0052,  0.0512,  0.0358],\n",
       "          [ 0.0566,  0.0071, -0.0091,  ..., -0.0162,  0.0306,  0.0220]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.0559,  0.0156,  0.0241,  ..., -0.0067,  0.0058,  0.0078],\n",
       "          [ 0.0324, -0.0052,  0.0170,  ..., -0.0112,  0.0345,  0.0151],\n",
       "          [ 0.0220,  0.0266,  0.0415,  ..., -0.0165,  0.0177,  0.0298],\n",
       "          ...,\n",
       "          [ 0.0414,  0.0120, -0.0122,  ..., -0.0210,  0.0117,  0.0362],\n",
       "          [ 0.0495,  0.0158, -0.0076,  ..., -0.0148,  0.0290,  0.0215],\n",
       "          [ 0.0390,  0.0178, -0.0135,  ..., -0.0165,  0.0371,  0.0219]],\n",
       " \n",
       "         [[ 0.0329, -0.0049,  0.0314,  ..., -0.0134,  0.0214, -0.0018],\n",
       "          [ 0.0194,  0.0259,  0.0443,  ..., -0.0124,  0.0152,  0.0277],\n",
       "          [ 0.0425,  0.0199, -0.0031,  ..., -0.0017,  0.0324,  0.0155],\n",
       "          ...,\n",
       "          [ 0.0496,  0.0158, -0.0076,  ..., -0.0148,  0.0291,  0.0211],\n",
       "          [ 0.0392,  0.0178, -0.0133,  ..., -0.0166,  0.0371,  0.0221],\n",
       "          [ 0.0485,  0.0306,  0.0036,  ..., -0.0140,  0.0255,  0.0379]],\n",
       " \n",
       "         [[ 0.0164,  0.0090,  0.0535,  ..., -0.0181,  0.0168,  0.0096],\n",
       "          [ 0.0407,  0.0181,  0.0103,  ..., -0.0022,  0.0292,  0.0125],\n",
       "          [ 0.0198,  0.0048,  0.0231,  ...,  0.0085,  0.0273,  0.0307],\n",
       "          ...,\n",
       "          [ 0.0394,  0.0178, -0.0137,  ..., -0.0164,  0.0371,  0.0215],\n",
       "          [ 0.0486,  0.0307,  0.0037,  ..., -0.0140,  0.0253,  0.0380],\n",
       "          [ 0.0449,  0.0311,  0.0005,  ..., -0.0062,  0.0334,  0.0229]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred,test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "039918dc88b27cfadd39191f5ad7c86954438832f838b9007c4d2ee23701c7b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
